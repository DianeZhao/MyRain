{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPTun6KUbk4GxxeGs3wAheY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"BgfBAQ3Cvc7b"},"outputs":[],"source":[""]},{"cell_type":"code","source":[""],"metadata":{"id":"EZ9YufiDPHH1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","import torch\n","import torch.nn as nn\n","import math"],"metadata":{"id":"ZanVweg1xY6x","executionInfo":{"status":"ok","timestamp":1647859247834,"user_tz":-60,"elapsed":8579,"user":{"displayName":"DANNING ZHAO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12037893343303948979"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["def try_gpu():\n","    \"\"\"\n","    If GPU is available, return torch.device as cuda:0; else return torch.device\n","    as cpu.\n","    \"\"\"\n","    if torch.cuda.is_available():\n","        device = torch.device('cuda:0')\n","    else:\n","        device = torch.device('cpu')\n","    return device"],"metadata":{"id":"8A-9KWEPDCk7","executionInfo":{"status":"ok","timestamp":1647859247838,"user_tz":-60,"elapsed":25,"user":{"displayName":"DANNING ZHAO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12037893343303948979"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["device=try_gpu()\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MNTFqjw7DD3b","executionInfo":{"status":"ok","timestamp":1647859248150,"user_tz":-60,"elapsed":331,"user":{"displayName":"DANNING ZHAO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12037893343303948979"}},"outputId":"c9710ad3-dd98-4c04-f8bf-071c7a887acb"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"code","source":["\"\"\"\n","According to Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\n","https://arxiv.org/pdf/1506.04214.pdf\n","\n","    ConvlutionalLSTM unit which has the following update rule:\n","        it ​= σ(W_xi * ​xt ​​+ W_hi * ​h(t−1) ​+ W_ci⊙c(t-1)+b_i​)\n","        ft​ = σ(W_xf * ​xt ​+ W_hf * ​h(t−1) ​+ W_cf⊙c(t-1)+b_f​)\n","        ct ​= ft​ ⊙ c(t−1) ​+ it ​⊙ ​tanh(W_xc * ​xt ​​+ W_hc * ​h(t−1) ​+ b_c​)  //c candidate\n","        ot ​= σ(W_xo * ​xt ​+ W_ho ​* h(t−1) ​+ W_co⊙c(t)+b_o​)\n","        \n","        ht ​= ot​ ⊙ tanh(ct​)​\n","        *:convolution operator\n","        ⊙:Hadamard product\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":94},"id":"Lw8hlfB_xhge","executionInfo":{"status":"ok","timestamp":1647796298346,"user_tz":-60,"elapsed":14,"user":{"displayName":"DANNING ZHAO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12037893343303948979"}},"outputId":"6ddf5861-0cbe-4672-961e-d20309b35310"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nAccording to Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\\nhttps://arxiv.org/pdf/1506.04214.pdf\\n\\n    ConvlutionalLSTM unit which has the following update rule:\\n        it \\u200b= σ(W_xi * \\u200bxt \\u200b\\u200b+ W_hi * \\u200bh(t−1) \\u200b+ W_ci⊙c(t-1)+b_i\\u200b)\\n        ft\\u200b = σ(W_xf * \\u200bxt \\u200b+ W_hf * \\u200bh(t−1) \\u200b+ W_cf⊙c(t-1)+b_f\\u200b)\\n        ct \\u200b= ft\\u200b ⊙ c(t−1) \\u200b+ it \\u200b⊙ \\u200btanh(W_xc * \\u200bxt \\u200b\\u200b+ W_hc * \\u200bh(t−1) \\u200b+ b_c\\u200b)  //c candidate\\n        ot \\u200b= σ(W_xo * \\u200bxt \\u200b+ W_ho \\u200b* h(t−1) \\u200b+ W_co⊙c(t)+b_o\\u200b)\\n        \\n        ht \\u200b= ot\\u200b ⊙ tanh(ct\\u200b)\\u200b\\n        *:convolution operator\\n        ⊙:Hadamard product\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["##Basic CONVLSTM model\n","\n","#function:init, init hidden,reset_parameter and forward\n","class convLSTM(nn.Module):\n","    \"\"\"\n","    ConvLSTM based on https://github.com/Hzzone/Precipitation-Nowcasting/blob/master/nowcasting/models/convLSTM.py\"\"\"\n","    def __init__(self,input_channels,hidden_channels,kernel_size=3,out_width=64,out_height=64,batch_first=False,bias=False,return_all_layers=False):\n","        \n","        #input channels, #of conv kernerls(hidden channels), convkernel size\n","        #output width, output height (also hidden width and height)are the same(64) with input according to MetNet paper\n","        \n","        \n","        super().__init__()\n","        \n","        self.input_channels = input_channels#defalut 256\n","        self.hidden_channels = hidden_channels#default 384\n","        self.kernel_size = kernel_size#default 3\n","        self.width=out_width#default 64\n","        self.height=out_height#default 64\n","        #self.batch_first = batch_first\n","        #self.bias = bias\n","        #self.return_all_layers = return_all_layers\n","        \n","        \n","        #W_xi,W_hi,W_xf,W_hf,W_xc,W_hc,W_xo,W_ho\n","        self.conv = nn.Conv2d(in_channels=input_channels + hidden_channels,##calculate the input xt and hidden ht together\n","                               out_channels=hidden_channels*4,##in order to cut it into gates according to channels\n","                               kernel_size=kernel_size,\n","                               stride=1,\n","                               padding=1)\n","        \"\"\"according to MetNet Paper, kernerlsize=3, in order \n","        to keep output rows and cols the same with input, default: stride=1 an padding=1\"\"\"\n","        \n","        self.reset_params()\n","        \n","\n","        \n","\n","    def init_hidden(self, inputs):\n","        #input shape (time_steps, bsz, 256, 64, 64)\n","        \"\"\"usage of torch new https://stackoverflow.com/questions/49263588/pytorch-beginner-tensor-new-method\"\"\"\n","        c0 = inputs.new(size=(inputs.size(1), self.hidden_channels, self.height, self.width))\n","        h0 = inputs.new(size=(inputs.size(1), self.hidden_channels, self.height, self.width))\n","        return h0, c0#dim(bsz,#filter,height,width)\n","\n","\n","    def reset_params(self):\n","        \"\"\"\n","        Initialize network parameters.\n","        \n","        std = 1.0 \n","        self.Wci.data.uniform_(-std, std)\n","        self.Wcf.data.uniform_(-std, std)\n","        self.Wco.data.uniform_(-std, std)\n","\"\"\"\n","        # if using requires_grad flag, torch.save will not save parameters in deed although it may be updated every epoch.\n","        # Howerver, if you use declare an optimizer like Adam(model.parameters()),\n","        # parameters will not be updated forever.\n","        self.Wci = nn.Parameter(torch.zeros(1, self.hidden_channels, self.height, self.width))\n","        self.Wcf = nn.Parameter(torch.zeros(1, self.hidden_channels, self.height, self.width))\n","        self.Wco = nn.Parameter(torch.zeros(1, self.hidden_channels, self.height, self.width))\n","\n","\n","    def forward(self, inputs):\n","        \"\"\"\n","        Expected input shape [seq_len, bsz, channels, height, width]\n","        input shape (seq_len, bsz, 256, 64, 64)\n","        output shape (seq_len, bsz, 384, 64, 64)\n","        \"\"\"\n","        \n","        #input shape (time_steps, bsz, 256, 64, 64)\n","        time_steps = len(inputs)\n","        self.hidden = self.init_hidden(inputs)##initial shapes of cell and hidden\n","        h, c = self.hidden\n","        \n","        print(\"shape h\",h.size())\n","        print(\"shape c\",c.size())\n","\n","        if inputs is None:\n","            x = torch.zeros((h.size(0), self.in_channels, self.height, self.width), dtype=torch.float)\n","            #(time_steps, bsz, 256, 64, 64)\n","        \n","        outputs = []\n","        for index in range(time_steps):#time_step\n","            # initial inputs\n","            x = inputs[index]\n","            #x,(bsz, 256, 64, 64) h,(bsz, hidden_channels, 64, 64) dim1:channel\n","            cat_xh = torch.cat([x, h], dim=1)#(bsz, 256+hidden_channels, 64, 64)\n","            conv_xh = self.conv(cat_xh)\n","            i, f, tmp_c, o = torch.chunk(conv_xh, 4, dim=1)###cut according to channel\n","            \n","           \n","            # conv lstm equations\n","            i = torch.sigmoid(i+self.Wci*c)\n","            f = torch.sigmoid(f+self.Wcf*c)\n","            c = f*c + i*torch.tanh(tmp_c)\n","            o = torch.sigmoid(o+self.Wco*c)\n","            h = o*torch.tanh(c)\n","\n","\n","            outputs.append(h)\n","       # print(\"outputsize\",outputs.size())\n","        outputs = torch.stack(outputs)#(time_steps, bsz, 384, 64, 64)convert list into tensor\n","        print(\"outputsize\",outputs.size())\n","\n","        return outputs, (h, c)#h,c last sequence"],"metadata":{"id":"_17iGxzXxhnL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ConvLSTMForecaster(nn.Module):\n","    # def __init__(self,input_channels,hidden_channels,kernel_size,out_width=64,out_height=64,batch_first=False,bias=False,return_all_layers=False):\n","    def __init__(self, \n","            in_channels: int,#default 256\n","            output_shape: tuple,#output shape (384, 64, 64)\n","            channels: tuple,#(hidden_channels384,32,)\n","            last_ts: bool = True,\n","            kernel_size: int = 3,\n","            last_relu: bool = True):\n","        super().__init__()\n","\n","        self.last_ts = last_ts\n","        self.forcatser = convLSTM(input_channels=in_channels, hidden_channels=channels[0], kernel_size=kernel_size,\n","                        out_width=output_shape[1], out_height=output_shape[2])\n","        #output shape (384, 64, 64)\n","        self.out_layer1 = nn.Conv2d(channels[0], channels[1], kernel_size=1)#default padding=0, stride=1\n","        self.out_layer2 = nn.Conv2d(channels[1], output_shape[0], 1)##output shape[0] 384\n","        self.height_weight = output_shape[1:]#(64,64)\n","        self.last_relu = last_relu\n","        self.relu = torch.nn.ReLU()\n","\n","    def forward(self, inputs):\n","        #inputs = inputs.permute(1,0,2,3,4) # time_steps first(depending on the dimension of input\n","        out, _ = self.forcatser(inputs)#the last sequence output\n","        \n","        if self.last_ts:\n","            out = out[-1]\n","        else:\n","            out = out.permute(1,0,2,3,4) # bsz_first\n","            bsz = len(out)\n","            print(\"forcaster bsz\",bsz)\n","            out = out.contiguous().view(bsz, -1, *self.height_weight) #view()=reshape(),the precondition of view is contiguous\n","            # use all time steps\n","\n","        out = self.out_layer1(out)\n","        print(\"out1\",out.size())\n","        out = self.out_layer2(out)\n","        print(\"out2\",out.size())\n","        if self.last_relu:\n","            out = self.relu(out)\n","        return out"],"metadata":{"id":"C9zgZCk9xqqN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"lDs9Eqr7IWg2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"89u9madCxq0u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ConvLSTM Model array size test.\n","\n","time_steps, batch_size, channels,height,width = 2, 3, 256,64,64\n","test_dataset= torch.randn((time_steps, batch_size, channels,height,width))\n","\n","#print(\"test_dataset\",test_dataset)"],"metadata":{"id":"oCzyfSbkybXI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##initilization of model\n","_, _, input_channels,batch_height,batch_width=test_dataset.size()\n","#print(\"sizes\",input_channels)\n","hidden_channels=200\n","#(input_channels,hidden_channels,kernel_size,out_width=64,out_height=64,batch_first=False,bias=False,return_all_layers=False)\n","conv_lstm=convLSTM(input_channels,hidden_channels)"],"metadata":{"id":"eahHVfV9zWcm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputset,(h,c)=conv_lstm(test_dataset)\n","\n","\n","print(\"output test\",outputset[1].size())\n","print(\"output test size\",outputset.size())\n","print(\"output test h\",h.size())\n","print(\"output test c\",c.size())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y0oQX05D0-Br","executionInfo":{"status":"ok","timestamp":1647796419699,"user_tz":-60,"elapsed":2386,"user":{"displayName":"DANNING ZHAO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12037893343303948979"}},"outputId":"f9b9fff4-4ee1-41a3-b56f-c96635f71839"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["shape h torch.Size([3, 200, 64, 64])\n","shape c torch.Size([3, 200, 64, 64])\n","outputsize torch.Size([2, 3, 200, 64, 64])\n","output test torch.Size([3, 200, 64, 64])\n","output test size torch.Size([2, 3, 200, 64, 64])\n","output test h torch.Size([3, 200, 64, 64])\n","output test c torch.Size([3, 200, 64, 64])\n"]}]},{"cell_type":"code","source":["#optimizer = torch.optim.SGD(conv_lstm.parameters(), lr=0.001, momentum=0.9)\n","for i,parameter in enumerate(conv_lstm.parameters()):\n","    print(i)\n","    print(parameter.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jDQuBpK-UhhG","executionInfo":{"status":"ok","timestamp":1647797051163,"user_tz":-60,"elapsed":284,"user":{"displayName":"DANNING ZHAO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12037893343303948979"}},"outputId":"776212d3-534c-4b08-f0e7-b212c7733598"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","torch.Size([1, 200, 64, 64])\n","1\n","torch.Size([1, 200, 64, 64])\n","2\n","torch.Size([1, 200, 64, 64])\n","3\n","torch.Size([800, 456, 3, 3])\n","4\n","torch.Size([800])\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"gsSt3C3yUhlL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"k_AL6G4WUhpx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"mJI1Nz7aUhsN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"t-Xcuy_NIXN8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#convforcatser initialization\n","convforcaster=ConvLSTMForecaster(in_channels=256,output_shape=(384,64,64),channels=(384,32))\n"],"metadata":{"id":"oNOTFfonIXSY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output=convforcaster(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nS7lpG9eIXWI","executionInfo":{"status":"ok","timestamp":1647797476251,"user_tz":-60,"elapsed":6477,"user":{"displayName":"DANNING ZHAO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12037893343303948979"}},"outputId":"f5b03bc6-e6db-4736-c3a3-a18e16d490f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["shape h torch.Size([3, 384, 64, 64])\n","shape c torch.Size([3, 384, 64, 64])\n","outputsize torch.Size([2, 3, 384, 64, 64])\n","out1 torch.Size([3, 32, 64, 64])\n","out2 torch.Size([3, 384, 64, 64])\n"]}]},{"cell_type":"code","source":["print(\"output\",type(output))\n","print(\"output\",output.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FeVws0PwIXY6","executionInfo":{"status":"ok","timestamp":1647797476252,"user_tz":-60,"elapsed":12,"user":{"displayName":"DANNING ZHAO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12037893343303948979"}},"outputId":"4319507a-8bac-4f5e-f800-ef165659f24b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["output <class 'torch.Tensor'>\n","output torch.Size([3, 384, 64, 64])\n"]}]},{"cell_type":"code","source":["for i,parameter in enumerate(convforcaster.parameters()):\n","    print(i)\n","    print(parameter.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KA8_etX-PImb","executionInfo":{"status":"ok","timestamp":1647797492326,"user_tz":-60,"elapsed":304,"user":{"displayName":"DANNING ZHAO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12037893343303948979"}},"outputId":"87ceab04-a72e-4dfa-ca58-11cf1d0efb4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","torch.Size([1, 384, 64, 64])\n","1\n","torch.Size([1, 384, 64, 64])\n","2\n","torch.Size([1, 384, 64, 64])\n","3\n","torch.Size([1536, 640, 3, 3])\n","4\n","torch.Size([1536])\n","5\n","torch.Size([32, 384, 1, 1])\n","6\n","torch.Size([32])\n","7\n","torch.Size([384, 32, 1, 1])\n","8\n","torch.Size([384])\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"IiGkqU2uPIuO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#####################################################\n","'''\n","in_channels = 1 # Black-white images in MNIST digits\n","hidden_channels = [5, 6]\n","out_features = 10 \n","\n","# Training parameters\n","learning_rate = 0.001\n","epochs = 3 \n","\n","# Initialize network\n","net = Net(in_channels, hidden_channels, out_features)\n","optimizer = torch.optim.SGD(net.parameters(), lr = learning_rate)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Define list to store losses and performances of each iteration\n","train_losses = []\n","train_accs = []\n","test_accs = []\n","\n","# Try using gpu instead of cpu\n","device = try_gpu()\n","\n","for epoch in range(epochs):\n","\n","    # Network in training mode and to device\n","    net.train()\n","    net.to(device)\n","\n","    # Training loop\n","    for i, (x_batch, y_batch) in enumerate(train_loader):\n","\n","        # Set to same device\n","        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","\n","        # Set the gradients to zero\n","        optimizer.zero_grad()\n","\n","        # Perform forward pass\n","        y_pred = net(x_batch)\n","\n","        # Compute the loss\n","        loss = criterion(y_pred, y_batch)\n","        train_losses.append(loss)\n","        \n","        # Backward computation and update\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Compute train and test error\n","    train_acc = 100*evaluate_accuracy(train_loader, net.to('cpu'))\n","    test_acc = 100*evaluate_accuracy(test_loader, net.to('cpu'))\n","    \n","    # Development of performance\n","    train_accs.append(train_acc)\n","    test_accs.append(test_acc)\n","\n","    # Print performance\n","    print('Epoch: {:.0f}'.format(epoch+1))\n","    print('Accuracy of train set: {:.00f}%'.format(train_acc))\n","    print('Accuracy of test set: {:.00f}%'.format(test_acc))\n","    print('')\n","    #######################zero grad##################################\n","\n","    def train(train_loader, model, optimizer, criterion, device):\n","    \"\"\"\n","    Trains network for one epoch in batches.\n","\n","    Args:\n","        train_loader: Data loader for training set.\n","        model: Neural network model.\n","        optimizer: Optimizer (e.g. SGD).\n","        criterion: Loss function (e.g. cross-entropy loss).\n","    \"\"\"\n","  \n","    avg_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    # Iterate through batches\n","    for i, data in enumerate(train_loader):#######################i:0-40,40份？？\n","        # Get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        #print(\"input\",input.size())#torch.Size([100, 40])\n","        # Move data to target device\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        print(\"i\",i)\n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Forward + backward + optimize\n","        outputs = model(inputs)#####################\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Keep track of loss and accuracy\n","        avg_loss += loss\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    return avg_loss / len(train_loader), 100 * correct / total'''\n","#################################without zero_grad  Adam#############################################"],"metadata":{"id":"rzztmT6QPIxL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##################defining optimizer#####################\n","##latitude-weighted Root-Mean-Squared-Error(RMSE)"],"metadata":{"id":"lL_oKAz_Ypf_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###############################train step,test step.################################\n","##structure according to assignment6 solution\n","def train(train_loader, model, optimizer, criterion, device):\n","    \"\"\"\n","    Trains network for one epoch in batches.\n","    Args:\n","        train_loader: Data loader for training set.\n","        model: Neural network model(ConvLSTM).\n","        optimizer: Optimizer (Adam).\n","        criterion: Loss function (latitude_weighted RMSE).\n","    \"\"\"\n","  \n","    avg_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    # Iterate through batches\n","    for i, data in enumerate(train_loader):#######################i:0-40,40份？？\n","        # Get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        #print(\"input\",input.size())#torch.Size([100, 40])\n","        # Move data to target device\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # Zero the parameter gradients\n","        optimizer.zero_grad()###\n","\n","        # Forward + backward + optimize\n","        outputs = model(inputs)#####################\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Keep track of loss and accuracy\n","        avg_loss += loss\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    return avg_loss / len(train_loader), 100 * correct / total"],"metadata":{"id":"RQoSiowHYppr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"EBhRCQAPYpsj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"URAIPipXPI8U"}}]}